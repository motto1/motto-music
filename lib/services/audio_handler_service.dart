/// Motto Music AudioHandler
/// å®Œå…¨åŸºäº namida çš„ BasicAudioHandler å®ç°
/// 
/// æ ¸å¿ƒç‰¹æ€§ï¼š
/// - ç»§æ‰¿è‡ªæœ¬åœ° BasicAudioHandlerï¼ˆæ¨¡æ‹Ÿ namida çš„ basic_audio_handler åŒ…ï¼‰
/// - å®Œæ•´ç§»æ¤ namida çš„æ’­æ”¾æ§åˆ¶é€»è¾‘
/// - vivo ç­‰å‚å•†ç³»ç»Ÿå…¼å®¹æ€§ä¿®å¤
/// - ä¿æŒä¸ PlayerProvider çš„æ¥å£å…¼å®¹

import 'package:audio_service/audio_service.dart';
import 'package:audio_session/audio_session.dart';
import 'package:just_audio/just_audio.dart';
import 'dart:async';
import '../core/basic_audio_handler.dart';
import 'audio_source_registry.dart';
import 'lyrics_notification_service.dart';

/// TrackItem - éŸ³é¢‘é¡¹åŒ…è£…ç±»
/// å®ç° Playable æ¥å£ä»¥å…¼å®¹ BasicAudioHandler
class TrackItem extends Playable {
  @override
  final String id;
  final MediaItem mediaItem;
  final String? audioUrl; // URL æˆ–æ–‡ä»¶è·¯å¾„
  final bool isFile; // æ˜¯å¦ä¸ºæœ¬åœ°æ–‡ä»¶
  final AudioVideoSource? audioSource; // LockCachingAudioSource
  final bool needsResolve; // æ˜¯å¦éœ€è¦å»¶è¿Ÿè§£æï¼ˆæ‡’åŠ è½½æ ‡è®°ï¼‰

  TrackItem({
    required this.id,
    required this.mediaItem,
    required this.audioUrl,
    this.isFile = true,
    this.audioSource,
    this.needsResolve = false,
  });

  /// ä» MediaItem åˆ›å»º TrackItem
  static TrackItem fromMediaItem(MediaItem item) {
    final sourceType = item.extras?['sourceType'] as String? ?? 'file';
    final sourcePath = item.extras?['sourcePath'] as String?;
    final needsResolve = item.extras?['needsResolve'] as bool? ?? false;
    AudioVideoSource? customAudioSource;
    String? resolvedPath = sourcePath ?? item.id;

    // æ‡’åŠ è½½é¡¹ç›®ï¼šä¸è®¾ç½® audioUrlï¼Œç­‰å¾…æ’­æ”¾æ—¶è§£æ
    if (sourceType == 'lazy' || needsResolve) {
      return TrackItem(
        id: item.id,
        mediaItem: item,
        audioUrl: null,
        isFile: false,
        needsResolve: true,
      );
    }

    if (sourceType == 'lock_caching' && sourcePath != null) {
      customAudioSource = AudioSourceRegistry.take(sourcePath);
      resolvedPath = null;
    }

    return TrackItem(
      id: item.id,
      mediaItem: item,
      audioUrl: resolvedPath,
      isFile: sourceType == 'file',
      audioSource: customAudioSource,
      needsResolve: false,
    );
  }
}

/// æ‡’åŠ è½½è§£æå›è°ƒç±»å‹
/// è¿”å›è§£æåçš„éŸ³é¢‘æºä¿¡æ¯ï¼š(url, headers, isFile)
typedef LazyResolveCallback = Future<(String? url, Map<String, String>? headers, bool isFile)?> Function(MediaItem item);

/// Motto AudioHandler - å®Œå…¨ç§»æ¤ namida æ¶æ„
class MottoAudioHandler extends BasicAudioHandler<TrackItem> {
  AudioSession? _audioSession;
  AndroidEqualizer? _equalizer;

  // ========== namida é˜²æŠ–æœºåˆ¶ï¼ˆå®Œå…¨ç§»æ¤ï¼‰==========
  DateTime? _lastPauseAt;
  bool _suppressNextPlay = false;

  // ========== æ‡’åŠ è½½è§£æå›è°ƒ ==========
  LazyResolveCallback? onLazyResolve;

  // ========== å‡è¡¡å™¨è®¿é—®å™¨ ==========
  AndroidEqualizer get equalizer => _equalizer ??= AndroidEqualizer();

  // ========== é€šçŸ¥æ æ­Œè¯æœåŠ¡ ==========
  final LyricsNotificationService _lyricsService = LyricsNotificationService();

  MottoAudioHandler() {
    _initAudioHandler();

    // â­ å…³é”®ï¼šç›‘å¬æ’­æ”¾çŠ¶æ€å˜åŒ–ï¼Œè‡ªåŠ¨å¹¿æ’­åˆ°UIå’Œé€šçŸ¥æ 
    isPlaying.addListener(() {
      print('[AudioHandler] ğŸ”„ æ’­æ”¾çŠ¶æ€å˜åŒ–: ${isPlaying.value}');
      _broadcastState(currentIndex.value);
    });
  }

  // ========== è¦†ç›–é€šçŸ¥æ ä½ç½®æ›´æ–°å›è°ƒ ==========
  @override
  void onNotificationPositionUpdate(int positionMs) {
    // è°ƒç”¨é€šçŸ¥æ æ­Œè¯æœåŠ¡æ›´æ–°æ’­æ”¾ä½ç½®ï¼ˆç”¨äºé€å­—é«˜äº®ï¼‰
    _lyricsService.updatePosition(positionMs);
  }

  // ========== åˆå§‹åŒ– ==========

  Future<void> _initAudioHandler() async {
    await _configureAudioSession();
    await _initializeEqualizer();
    print('[AudioHandler] âœ… åˆå§‹åŒ–å®Œæˆï¼ˆnamida æ¶æ„ï¼‰');
  }

  Future<void> _configureAudioSession() async {
    try {
      _audioSession = await AudioSession.instance;
      await _audioSession!.configure(const AudioSessionConfiguration.music());

      // ç›‘å¬éŸ³é¢‘ä¸­æ–­ï¼ˆæ‹”å‡ºè€³æœºç­‰ï¼‰
      _audioSession!.becomingNoisyEventStream.listen((_) {
        if (isPlaying.value) {
          pause();
        }
      });
    } catch (e) {
      print('[AudioHandler] âš ï¸ AudioSession é…ç½®å¤±è´¥: $e');
    }
  }

  Future<void> _initializeEqualizer() async {
    try {
      await equalizer.setEnabled(true);
      print('[AudioHandler] âœ… å‡è¡¡å™¨å·²å¯ç”¨');
    } catch (e) {
      print('[AudioHandler] âš ï¸ å‡è¡¡å™¨åˆå§‹åŒ–å¤±è´¥: $e');
    }
  }

  // ========== namida æ ¸å¿ƒï¼šæ’­æ”¾æ§åˆ¶é€»è¾‘ï¼ˆå®Œå…¨ç§»æ¤ï¼‰==========

  @override
  Future<void> play() async {
    print('[AudioHandler] â–¶ï¸ play() è°ƒç”¨ (suppressNext: $_suppressNextPlay, æ’­æ”¾ä¸­: ${isPlaying.value})');

    // â­ namida é˜²æŠ–é€»è¾‘ - é˜²æ­¢ vivo ç­‰å‚å•†å¼‚å¸¸å›è°ƒ
    if (_suppressNextPlay) {
      final now = DateTime.now();
      if (_lastPauseAt != null) {
        final diff = now.difference(_lastPauseAt!).inMilliseconds;
        if (diff < 500) {
          print('[AudioHandler] â å¿½ç•¥æš‚åœå ${diff}ms å†…çš„ play (vivo å…¼å®¹ä¿®å¤)');
          _suppressNextPlay = false;
          return;
        }
        print('[AudioHandler] â±ï¸ è·æš‚åœ ${diff}msï¼Œæ¸…é™¤é˜²æŠ–æ ‡å¿—');
      }
      _suppressNextPlay = false;
    }

    try {
      await _audioSession?.setActive(true);
      await super.play();
      print('[AudioHandler] âœ… play() æ‰§è¡Œå®Œæˆ');
    } catch (e) {
      print('[AudioHandler] âŒ play() å¤±è´¥: $e');
    }
  }

  @override
  Future<void> pause() async {
    print('[AudioHandler] â¸ï¸ pause() è°ƒç”¨ (æ’­æ”¾ä¸­: ${isPlaying.value})');

    // â­ namida é˜²æŠ–è®¾ç½®
    _lastPauseAt = DateTime.now();
    _suppressNextPlay = true;

    try {
      await super.pause();
      // âš ï¸ å…³é”®ï¼šä¸è°ƒç”¨ setActive(false)ï¼Œé¿å… vivo ç³»ç»Ÿå¼‚å¸¸å›è°ƒ
      print('[AudioHandler] âœ… pause() æ‰§è¡Œå®Œæˆ');
    } catch (e) {
      print('[AudioHandler] âŒ pause() å¤±è´¥: $e');
    }
  }

  @override
  Future<void> stop() async {
    print('[AudioHandler] â¹ï¸ stop() è°ƒç”¨');
    await super.stop();
    await _audioSession?.setActive(false);
  }

  // ========== æ’­æ”¾é¡¹ç®¡ç†ï¼ˆnamida æ¨¡å¼ï¼‰==========

  @override
  Future<void> onItemPlay(
    TrackItem item,
    int index,
    Function skipItem,
    dynamic preparedItemInfo,
  ) async {
    print('[AudioHandler] ğŸµ æ’­æ”¾: ${item.mediaItem.title} (ç´¢å¼•: $index)');

    try {
      String? audioUrl = item.audioUrl;
      Map<String, String>? headers = item.mediaItem.extras?['headers'] as Map<String, String>?;
      bool isFile = item.isFile;

      // â­ æ‡’åŠ è½½å¤„ç†ï¼šå¦‚æœéœ€è¦è§£æï¼Œè°ƒç”¨å›è°ƒè·å–éŸ³é¢‘æº
      if (item.needsResolve) {
        print('[AudioHandler] ğŸ”„ æ‡’åŠ è½½é¡¹ç›®ï¼Œå¼€å§‹è§£æéŸ³é¢‘æº...');

        if (onLazyResolve != null) {
          final resolved = await onLazyResolve!(item.mediaItem);
          if (resolved != null) {
            audioUrl = resolved.$1;
            headers = resolved.$2;
            isFile = resolved.$3;
            final urlPreview = audioUrl != null && audioUrl.length > 50
                ? '${audioUrl.substring(0, 50)}...'
                : audioUrl ?? 'null';
            print('[AudioHandler] âœ… æ‡’åŠ è½½è§£æå®Œæˆ: $urlPreview');
          } else {
            print('[AudioHandler] âŒ æ‡’åŠ è½½è§£æå¤±è´¥ï¼Œè·³è¿‡æ­¤æ›²ç›®');
            skipItem();
            return;
          }
        } else {
          print('[AudioHandler] âš ï¸ æœªè®¾ç½®æ‡’åŠ è½½å›è°ƒï¼Œè·³è¿‡æ­¤æ›²ç›®');
          skipItem();
          return;
        }
      }

      if (headers != null) {
        print('[AudioHandler] ğŸ”‘ æå–åˆ° headers: ${headers.keys.join(", ")}');
      }

      // è®¾ç½®éŸ³é¢‘æºï¼ˆä½¿ç”¨ URL å­—ç¬¦ä¸²ï¼‰
      final duration = await setSource(
        audioUrl,
        item: item,
        index: index,
        isFile: isFile,
        headers: headers,
        audioSource: item.audioSource,
      );

      // æ›´æ–°åª’ä½“ä¿¡æ¯åˆ°é€šçŸ¥æ 
      mediaItem.add(item.mediaItem);
      _broadcastState(index);

      // å¦‚æœè®¾ç½®äº†è‡ªåŠ¨æ’­æ”¾
      if (playWhenReady.value) {
        await _audioSession?.setActive(true);
        await player.play();
      }

      print('[AudioHandler] âœ… æ’­æ”¾è®¾ç½®å®Œæˆ (æ—¶é•¿: $duration)');
    } catch (e, stack) {
      print('[AudioHandler] âŒ æ’­æ”¾å¤±è´¥: $e\n$stack');
      // æ’­æ”¾å¤±è´¥æ—¶è·³è¿‡
      skipItem();
    }
  }

  void _broadcastState(int itemIndex) {
    final event = PlaybackEvent(
      processingState: player.processingState,  // ç›´æ¥ä½¿ç”¨ ProcessingState
      updateTime: DateTime.now(),
      updatePosition: Duration(milliseconds: currentPositionMS.value),
      bufferedPosition: player.bufferedPosition,
      duration: currentItemDuration.value,
      currentIndex: itemIndex,
    );

    playbackState.add(transformEvent(event, false, itemIndex));
  }

  /// æ˜ å°„ ProcessingState åˆ° AudioProcessingState
  AudioProcessingState _mapProcessingState(ProcessingState state) {
    switch (state) {
      case ProcessingState.idle:
        return AudioProcessingState.idle;
      case ProcessingState.loading:
        return AudioProcessingState.loading;
      case ProcessingState.buffering:
        return AudioProcessingState.buffering;
      case ProcessingState.ready:
        return AudioProcessingState.ready;
      case ProcessingState.completed:
        return AudioProcessingState.completed;
      default:
        return AudioProcessingState.idle;
    }
  }

  @override
  Future<void> onQueueChanged() async {
    await super.onQueueChanged();
    print('[AudioHandler] ğŸ“‹ é˜Ÿåˆ—æ›´æ–° (é•¿åº¦: ${currentQueue.queueRx.value.length})');
  }

  // ========== namida é€šçŸ¥æ é…ç½®ï¼ˆå®Œå…¨ç§»æ¤ï¼‰==========

  @override
  PlaybackState transformEvent(
    PlaybackEvent event,
    bool isItemFavourite,
    int itemIndex,
  ) {
    return playbackState.value.copyWith(
      controls: [
        MediaControl.skipToPrevious,
        if (isPlaying.value) MediaControl.pause else MediaControl.play,
        MediaControl.skipToNext,
        MediaControl.stop,
      ],
      systemActions: const {
        MediaAction.seek,
        MediaAction.playPause,
        MediaAction.play,
        MediaAction.pause,
        MediaAction.skipToNext,
        MediaAction.skipToPrevious,
        MediaAction.stop,
      },
      androidCompactActionIndices: const [0, 1, 2],
      processingState: _mapProcessingState(event.processingState),  // æ˜ å°„ç±»å‹
      playing: isPlaying.value,
      updatePosition: event.updatePosition,
      bufferedPosition: event.bufferedPosition,
      speed: player.speed,
      queueIndex: itemIndex,
    );
  }

  // ========== å…¼å®¹å±‚æ–¹æ³• - ä¿æŒä¸ PlayerProvider çš„å…¼å®¹ ==========

  /// è®¾ç½®æ’­æ”¾åˆ—è¡¨ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
  Future<void> setPlaylist(List<MediaItem> items, {int initialIndex = 0}) async {
    print('[AudioHandler] ğŸ“‹ è®¾ç½®æ’­æ”¾åˆ—è¡¨: ${items.length} é¦–, èµ·å§‹: $initialIndex');

    final trackItems = items.map((item) => TrackItem.fromMediaItem(item)).toList();

    await assignNewQueue(
      queue: trackItems,
      playAtIndex: initialIndex,
      startPlaying: false, // é»˜è®¤ä¸è‡ªåŠ¨æ’­æ”¾
    );
  }

  /// æ·»åŠ åˆ°é˜Ÿåˆ—ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
  @override
  Future<void> addQueueItem(MediaItem item) async {
    final trackItem = TrackItem.fromMediaItem(item);
    await addToQueue(trackItem);
    print('[AudioHandler] â• æ·»åŠ åˆ°é˜Ÿåˆ—: ${item.title}');
  }

  /// ä»é˜Ÿåˆ—ç§»é™¤ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
  @override
  Future<void> removeQueueItem(MediaItem item) async {
    final index = currentQueue.queueRx.value.indexWhere((i) => i.id == item.id);
    if (index >= 0) {
      await removeFromQueue(index);
      print('[AudioHandler] â– ä»é˜Ÿåˆ—ç§»é™¤: ${item.title}');
    }
  }

  // ========== ä¾¿æ·è®¿é—®å™¨ï¼ˆPlayerProvider å…¼å®¹ï¼‰==========

  /// è·å–å½“å‰æ’­æ”¾ä½ç½®
  Duration get position => player.position;

  /// è·å–å½“å‰æ’­æ”¾çŠ¶æ€
  bool get playing => isPlaying.value;

  /// è·å–éŸ³é¢‘æ—¶é•¿
  Duration? get duration => currentItemDuration.value;

  /// è·å–å½“å‰ç´¢å¼•
  int get currentQueueIndex => currentIndex.value;

  /// è·å–æ’­æ”¾é˜Ÿåˆ—ï¼ˆå…¼å®¹è®¿é—®ï¼‰
  List<TrackItem> get queueList => currentQueue.queueRx.value;

  // ========== èµ„æºæ¸…ç† ==========

  Future<void> dispose() async {
    _suppressNextPlay = false;
    _lastPauseAt = null;
    await onDispose();
    // AndroidEqualizer ä¼šéšæ’­æ”¾å™¨è‡ªåŠ¨é‡Šæ”¾
    print('[AudioHandler] ğŸ—‘ï¸ èµ„æºé‡Šæ”¾å®Œæˆ');
  }
}
